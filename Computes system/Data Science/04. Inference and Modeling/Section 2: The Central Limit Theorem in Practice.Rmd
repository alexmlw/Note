---
title: 'Section 2: The Central Limit Theorem in Practice'
author: "Alexander Troynin"
date: "18 07 2018"
output: html_document
---

### The Central Limit Theorem in Practice

Центральная предельная теорема говорит нам, что функция распределения для суммы ничьих
приблизительно нормальна. Мы также узнали, что при делении нормально распределенной
случайной величины на неслучайную константу результирующая случайная величина также
нормально распределена.

Это означает, что распределение $\bar{X}$ является приблизительно нормальным.
Таким образом, в итоге, мы имеем, что $\bar{X}$ имеет приблизительно нормальное 
распределение. И в предыдущей теме мы определили, что ожидаемое значение p, а
стандартная ошибка-квадратный корень из p раз 1 минус p, деленный на размер выборки N.

Итак, как это нам поможет?

Давайте зададим примерный вопрос.

Предположим, мы хотим знать, какова вероятность того, что мы находимся в пределах
одного процентного пункта от p. Что мы сделали очень, очень хорошую оценку? Таким
образом, мы в основном спрашиваем, какова вероятность того, что расстояние между
$\bar{X}$ и p, абсолютное значение $\bar{X} - p < 0,01$, 1 процентный пункт. Мы
можем использовать то, что мы научились видеть, это все равно что спросить, какова вероятность того, что $\bar{X} <= p +- 0.01$ вероятность $\bar{X} <= p - 0.01.$

Теперь мы можем ответить вопрос?

Можем вычислить эту вероятность?

Обратите внимание, что можем использовать математический трюк, который мы узнали в
предыдущем модуле.

Что это был за трюк?

Мы вычитаем ожидаемое значение и делим на стандартную ошибку с обеих сторон уравнения.
Это дает нам стандартную нормальную переменную, которую мы называем заглавной Z, с левой 
стороны.

И мы знаем, как сделать расчеты для этого.

Поскольку p-ожидаемое значение, а стандартная ошибка x-бара-квадратный корень из p раз 1 минус p, деленный на N, мы получаем, что вероятность, которую мы только что вычисляли, эквивалентна вероятности Z, нашей стандартной нормальной переменной,
менее чем 0,01 деленный на стандартную ошибку х-бар, минус вероятность Z быть меньше, чем минус 0.01 разделены, что стандартная ошибка х-бар.
Хорошо, теперь мы можем вычислить эту вероятность?
Еще.
Наша проблема в том, что мы не знаем p.
Таким образом, мы не можем вычислить стандартную ошибку x-bar, используя только данные.
Но оказывается - и это что-то новое, что мы показываем вам-что CLT все еще работает, если мы используем оценку стандартной ошибки, которая вместо p использует X-bar на своем месте.
Мы говорим, что это плагин оценки.
Мы называем это оценкой плагина.
Поэтому наша оценка стандартной ошибки-это квадратный корень из x-bar умноженный на 1 минус X-bar деленный на N. обратите внимание, что мы изменили p для X-bar.
В математической формуле, которую мы показываем, вы можете увидеть шляпу поверх SE.
В учебниках по статистике мы используем такую маленькую шляпу для обозначения оценок.
Это оценка стандартной ошибки, а не фактической стандартной ошибки.
Но, как мы уже говорили, Центральная предельная теорема все еще работает.
Обратите внимание, что, что важно, что эта оценка действительно может быть построена с использованием наблюдаемых данных.
Теперь, давайте продолжим наши расчеты.
Но теперь вместо деления на стандартную ошибку мы будем делить на эту оценку стандартной ошибки.
Вычислим оценки стандартной ошибки для первого образца, который мы приняли, в котором у нас было 12 синих шариков и 13 красных бусин.
В этом случае X-бар был 0.48.
Чтобы вычислить стандартную ошибку, мы просто пишем этот код.
И мы получим, что это около 0,1.
Теперь мы можем ответить на вопрос.
Теперь мы можем вычислить вероятность быть настолько близко к p, насколько мы хотели.
Мы хотели быть на расстоянии 1 процентного пункта.
Ответ просто pnorm 0,01 - это 1 процентный пункт--
разделенным на это по оценкам ГП минус pnorm негативных 0.01 разделен по оценкам ГП.
Мы включим это в R, и получим ответ.
Ответ заключается в том, что вероятность этого составляет около 8%.
Таким образом, есть очень небольшой шанс, что мы будем так же близки к фактической пропорции.
Это было не очень полезно, но что мы сможем сделать с центральной предельной теоремой, так это определить, какие размеры выборки лучше.
И как только мы получим эти большие размеры выборки, мы сможем дать очень хорошую оценку и некоторые очень информативные вероятности.

### Margin of Error

Таким образом, опрос только 25 человек не очень полезен, по крайней мере, для близких выборов.
Ранее мы упоминали погрешность.
Теперь мы можем определить его, потому что это просто в 2 раза стандартная ошибка, которую мы теперь можем оценить.
В нашем случае это было 2 раза se, что составляет около 0,2.
Почему мы умножаем на 2?
Это потому, что если вы спросите, какова вероятность того, что мы находимся в пределах 2 стандартных ошибок от p, используя те же предыдущие уравнения, мы в конечном итоге с уравнением, как этот.
Это упрощает, и мы просто спрашиваем, какова вероятность стандартного нормального распределения, которое имеет ожидаемое значение 0, а стандартная ошибка one находится в пределах двух значений от 0, и мы знаем, что это около 95%.
Таким образом, вероятность того, что X-bar окажется в пределах 2 стандартных ошибок, составляет 95%.
Это предел погрешности, в нашем случае, до p.
Почему мы используем 95%?
Это несколько произвольно.
Но традиционно, это то, что было использовано.
Это наиболее распространенное значение, используемое для определения полей ошибок.
Таким образом, Центральная предельная теорема говорит нам, что наш опрос, основанный на выборке всего 25, не очень полезен.
Мы не очень много узнаем, когда погрешность так велика.
Все, что мы действительно можем сказать, это то, что народное голосование не будет выиграно с большим отрывом.
Вот почему опросники, как правило, используют большие размеры выборки.
Из таблицы, которую мы показали ранее из RealClearPolitics, мы увидели, что типичный Размер выборки составляет от 700 до 3500.
Чтобы увидеть, как это дает нам гораздо более практический результат, обратите внимание, что если бы мы получили x-бар 0,48, но с размером выборки 2,000, расчетная стандартная ошибка была бы около 0,01.
Таким образом, наш результат-оценка 48% синих бусин с погрешностью 2%.
В этом случае результат будет гораздо более информативным и заставит нас думать, что красных бусин больше, чем синих.
Но имейте в виду, это просто гипотетически.
Мы не взяли опрос 2000 бусин, так как не хотим испортить соревнование.

### A Monte Carlo Simulation for the CLT

Предположим, мы хотим использовать Моделирование Монте-Карло, чтобы подтвердить, что инструменты, которые мы использовали для построения оценок и погрешностей с использованием теории вероятностей, действительно работают.
Чтобы создать симуляцию, нам нужно написать такой код.
Мы просто напишем модель урны, используем replicate для построения моделирования Монте-Карло.
Проблема, конечно, в том, что мы не знаем p.
Мы не можем запустить код, который только что показали, потому что не знаем, что такое p.
Тем не менее, мы могли бы построить урну, подобную той, которую мы показали в предыдущем видео, и фактически запустить аналоговое моделирование.
Это заняло бы много времени, потому что вы собирали бы бусины и подсчитывали их, но вы могли бы взять 10000 образцов, подсчитывать бусины каждый раз и отслеживать пропорции, которые вы видите.
Мы можем использовать функцию Take poll с n из 1000 вместо того, чтобы рисовать из урны, но это все равно займет время, потому что вам нужно будет подсчитать бусины и ввести результаты в R.
Чтобы подтвердить теоретические результаты, мы можем выбрать значение p или несколько значений p, а затем провести моделирование с их помощью.
Для примера установим p равным 0.45.
Мы можем смоделировать один опрос 1000 бусин или людей, используя этот простой код.
Теперь мы можем взять это в симуляцию Монте-Карло.
Сделайте это 10000 раз, каждый раз возвращая долю синих бусин, которые мы получаем в нашем образце.
Для обзора теория говорит нам, что x-бар имеет приблизительно нормальное распределение с ожидаемым значением 0.45 и стандартной ошибкой около 1.5%.
Моделирование это подтверждает.
Если мы возьмем среднее значение X-hats, которые мы создали, мы действительно получим значение около 0,45.
И если мы вычислим sd значений, которые мы только что создали, мы получим значение около 1,5%.
Гистограмма и график qq этих данных X-hat подтверждают, что нормальное приближение также является точным.
Опять же, обратите внимание, что в реальной жизни мы никогда не сможем запустить такой эксперимент, потому что мы не знаем p.
Но мы могли бы запустить его для различных значений p и размеров выборки N и увидеть, что теория действительно хорошо работает для большинства значений.
Вы можете легко сделать это самостоятельно, перезапустив код, который мы показали Вам после изменения p И N.

### The Spread

Конкуренция заключается в прогнозировании спреда, а не доли р.
Однако, поскольку мы предполагаем, что есть только две стороны, мы знаем, что спред составляет всего p минус (1 минус p), Что равно 2p минус 1.
Таким образом, все, что мы сделали, можно легко адаптировать к оценке p минус 1.
Как только у нас есть наша оценка, x-bar, и наша оценка нашей ошибки tandard X-bar, мы оцениваем спред в 2 раза x-bar минус 1, просто подключая X-bar, где у вас должно быть p.
И, поскольку мы умножаем случайную величину на 2, мы знаем, что стандартная ошибка увеличивается на 2.
Таким образом, стандартная ошибка этой новой случайной величины в 2 раза больше стандартной ошибки x-бара.
Обратите внимание, что вычитание 1 не добавляет изменчивости, поэтому оно не влияет на стандартную ошибку.
Итак, для нашего первого примера, только с 25 бусин, наша оценка p
был 0.48 с погрешностью 0.2.
Это означает, что наша оценка спреда составляет 4 процентных пункта, 0.04, с погрешностью 40%, 0.4.
Опять же, не очень полезный Размер выборки.
Но дело в том, что оценка и стандартная ошибка 
или p, Мы имеем его для спреда 2P минус 1.

### Bias: Why Not Run a Very Large Poll?

Обратите внимание, что для реалистичных значений p, скажем, между 0,35 и 0,65 для народного голосования, если мы проведем очень большой опрос, скажем, 100 000 человек, теория скажет нам, что мы почти идеально предсказали бы выборы, поскольку максимально возможная погрешность составляет около 0,3%.
Вот расчеты, которые были использованы для определения этого.
Мы можем видеть график, показывающий нам стандартную ошибку для нескольких значений p, Если мы зафиксируем N равным 100,000.
Так почему же нет опросов общественного мнения, которые проводят такие большие опросы?
Одна из причин заключается в том, что проведение опросов с размером выборки 100 000 очень дорого.
Но, возможно, более важной причиной является то, что теория имеет свои ограничения.
Опрос намного сложнее, чем сбор шариков из урны.
Например, в то время как бусины либо красные, либо синие, и вы можете видеть это своими глазами, люди, когда вы спрашиваете их, могут лгать вам.
Кроме того, поскольку вы проводите эти опросы обычно по телефону, вы можете пропустить людей, у которых нет телефонов.
И они могут голосовать по-разному.
Но, возможно, самым разным способом фактического опроса от нашей модели урны является то, что мы на самом деле не знаем точно, кто в нашей популяции, а кто нет.
Как мы узнаем, кто будет голосовать?
Мы охватим всех возможных избирателей?
Таким образом, даже если наша погрешность очень мала, может быть не совсем верно, что наше ожидаемое значение p.
Мы называем это предвзятостью.
Исторически сложилось так, что опросы действительно предвзяты, хотя и не настолько.
Типичное смещение составляет от 1% до 2%.
Это делает прогнозирование выборов немного более интересным.
И мы поговорим об этом в следующем видео.